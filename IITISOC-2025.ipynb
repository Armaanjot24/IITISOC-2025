{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d32a3891",
    "outputId": "0a4017f4-2fa6-46ef-f671-b714f6020407"
   },
   "outputs": [],
   "source": [
    "!pip install transformers diffusers lpips accelerate\n",
    "!pip install torch torchvision\n",
    "!pip install diffusers[torch]\n",
    "!pip install tqdm pillow matplotlib ipython numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "m4mqmjcdJolW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "from torch import autocast\n",
    "from torchvision import transforms as tfms\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, LMSDiscreteScheduler\n",
    "from diffusers.models.attention import BasicTransformerBlock\n",
    "import torch.nn.utils.prune as prune\n",
    "from accelerate import cpu_offload_with_hook\n",
    "from lpips import LPIPS\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nUNbOeMkK9y4",
    "outputId": "d1dd0389-bc91-4694-f6d7-7463f2fc5f12"
   },
   "outputs": [],
   "source": [
    "use_amp = torch.cuda.is_available()\n",
    "if use_amp:\n",
    "    print(\"AMP enabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ebl_6hezLAaJ",
    "outputId": "92594c5a-aa65-431e-b01e-86c3eae77dc7"
   },
   "outputs": [],
   "source": [
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {torch_device}\")\n",
    "\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9cf2eef4157c419ba1c44d40f9878265",
      "b6b6565fcddd454db4b94a1a84b063f8",
      "2c3cd61feeb9435ea981d1659eec3b28",
      "ec1faecbaf7745578437f10e155f215f",
      "09dfc406695e4094897be56fec2e6fb0",
      "79fcf707d3994823bb04bfb4bac615ab",
      "021eb4caf13c4daeaecd1b979a9902cb",
      "7158346a730b4c26801bda0e6447bc45",
      "f4e1374bc444445a90ba89ca689dcccf",
      "083c8787e0ec4b67a9776f4abf46bf2f",
      "449b82ae3fbb41cdaa74b82dc9523951",
      "d3baa8088e974af9a868e78054b495f5",
      "0c131a62d2144784a92583a18d3f85eb",
      "ad1f0a02d5a94d3a8fb6b38c4c7aecfe",
      "8fcc12d0c3104fcbbbe31407941f9828",
      "0812ac7ad4c340a083744e7bcaded4c3",
      "f1a5f07c17b34febb62a64cbf9f8ef54",
      "0b882f1602874a00ae2c232dfd658ab7",
      "97a3641fb1074f138602063219098cf1",
      "606a8c0e36b547a29b02d523e34da9b6",
      "bbf565671c7a472b9a50921ab5dfb36f",
      "e9263cff4de4442eaea34f9fdba0cba7",
      "5550542fa279476b9c65f4951931185c",
      "af75b0337d744ee99a43b7c97e233f9e",
      "ac7848e4c49d4313a366381f883358fa",
      "c583487afb4e4a4db9f527866654b6f3",
      "cbb92048853f494fbc0269c68a135736",
      "ca6d296ce2554c538fec56d62523fad7",
      "4580c181a8464fceb152029e6debe7e2",
      "9cb52897687a404ca557e4c6e7195a77",
      "7ae1865ebcf94391ba39a8437bf2b173",
      "46bf7a94253f4c5caec4d73a6e122544",
      "03ecc20370fb4f27ac0046bd421d6cd2",
      "9936b6e50fa54db99d9e17168c911d91",
      "42fdfffbbccf439fa05c6ac10901d4b2",
      "858817476a89483f8ffb392c87353cd7",
      "5b64278db19e4048a322abe0940c80d3",
      "27c44dac6e154eb1866f1a44b3ec7dc7",
      "36198e2b5ebd47b6bc5e9e97f73a63b5",
      "0a8824d838a048a888bf73ef4bd9cd5d",
      "7e2ff66d1f3a4341b1e18d9c16caf090",
      "cf04721f10eb4dbd8cf3ed850da812ad",
      "abe0f69970cc409cb2474db68689db8f",
      "7a27bfa807d74ccd95121479b01d560a",
      "6d029848b0a74e4fad05c17acb57e8dc",
      "b7c01e1de3dd47e2a683c336b5b3817b",
      "21b0b28b234a43ef907402fdc1b53f70",
      "f95bbb06ad36464387568bef8cdd172e",
      "71de80eb300e4588afec871a220d6f1d",
      "0ea80b28324d424fb86a31b0bd4d3de3",
      "acddb2d687394a0f8a2c62bca3f7b0bd",
      "06f5facc92794964bd3eb368fed7aa44",
      "736a8d9aa8e749e3a5cf8693c202facb",
      "d9e42f4c9fd34ef9a28b2ce133c0516f",
      "f63d6d8c93fd430abf4312579bef2afc",
      "f3dedff92a554c7781ceb0b43cda8c73",
      "c2f4c15b467041279b87d958cdf3446f",
      "fefe0b56e3ef4d65a9770e014e5f9f6c",
      "8bb18c8f0edf48b98706dc2e759abbe9",
      "fa07732f39ff472b85b818d7cc95b641",
      "8dfbbd145eaa4d9ea8f55599ed80d40a",
      "91d2ae68f8d043bd8a4f627390abd597",
      "5090218e455b458c913b29e159047e43",
      "88ecf8fc62a1430eb9229afe42c0f9b1",
      "7ed9b24991e6449ea6b33cd399456c79",
      "1c9649403a784e11be0b84f4db4f50a9",
      "22bc26292617411fa17bd50b494d5486",
      "d23890c5acc249b6b6f4d0b4f1b5f94c",
      "f84499348b084aefb4a5a92cad6340b6",
      "5af6c316b82e43e0889787e9112f06ad",
      "29b7beea79094710a8e8c5df6168b0e9",
      "dbf3b134163e4865b98086859987051f",
      "5d050192df8b45cd939a8099b56a1c6d",
      "0cf6aa0113c74513819169b795bed70b",
      "848ad2b94e9346aca2ca179137c4a4bb",
      "58dfda84406b44fcb7c8dfa61feebdbd",
      "452673af976c4217a0992eefe7bd1aea",
      "4f3269e3055d4f74967c7c2491c0f0f7",
      "56cfc0ce020d4a6f91728614389101dc",
      "6176601e251b43ef881b29ee6481503a",
      "dd34de19c0bc4ffdbac20f5bd24fc883",
      "e712a1aa4ed44fb1857099ea858705e8",
      "f739dcfffc4a4858bec94bd734f943e0",
      "90424609aaae4aa789fee0eb0c17991b",
      "d3bd753b00c64c278be182f155381bc7",
      "9cd48f8eeccb469a9e35f5fd17ad7fff",
      "08c48b138c4240b4bb9f612e5ddc187f",
      "87201bd79d654faa9969759f55f47aae",
      "257e55d6c0a44df28ec06771820e684d",
      "0b58c75e57504dd193719f1ed2de22a5",
      "eeda4918ca1b4c6aa4aac525d59030df",
      "6dd172ed2cc94cdf8d906e176c2d97b1",
      "6354504ad306452184b7e89709312a3a",
      "f1b157c3e28b455fb917b1ed257a9518",
      "e7dccd4f33384ca8819bc676bf3afbea",
      "0c82fa813df14e1683a7e2315eecaf9a",
      "dcd8ab5265424248a0e71a36795dd04a",
      "ea33f21d9ccf4b9aa0f29e8bb03a66c5",
      "6d575b5664a44306a6d58c47e6d8260e",
      "dbcd8277848a449e87cace9e2e84c7b4",
      "d54cc899cc4b45edb92487d347d60db1",
      "d4782e60287d4db1bb223cb20d202843",
      "f802793be8d84038af4cfacab34d4c24",
      "feba199b3abf42af8a082cfc5df0869c",
      "bff491042fea4a028d4df57a7800f51b",
      "35a7e7c27a8d4b6ea9042e8a0464962b",
      "620403f38388497b93bc64742903d210",
      "29ae95e6fc2246f6a06ae26177ef3032",
      "893da5c0e8224a6ebf73c5ba0dc03203",
      "53ff313d19874117ae54f9d1b708fc54",
      "d7295d01156340f194e1619b15653a5d",
      "a4440bffb4fa42ffbb139222fa6b17ec",
      "b298645874964eae87d5c6d4854a04bf",
      "9b0d0b8afb214ca0b948a011629f1f90",
      "c5f066967688485ab2702ff8132b67a7",
      "fbc3f61a5e924c6eb88718ff3ad1065d",
      "8182395966654b149b7ce13b92ccd8f6",
      "f2484f296a2d4525aa3d2e567387a79e",
      "8f229a5cb1664657aab56e3d32178b72",
      "c36d8e16ff2d46b68fad212bf5527ec1",
      "00c0527913994b2fb1916e4174262625"
     ]
    },
    "id": "8Hy-AF-wLCCc",
    "outputId": "4f9d45e5-3c2e-49d3-999c-fbf30a99f38d"
   },
   "outputs": [],
   "source": [
    "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\", use_auth_token=True)\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "unet = UNet2DConditionModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\", use_auth_token=True)\n",
    "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "Z322txzVLEBQ"
   },
   "outputs": [],
   "source": [
    "unet.enable_gradient_checkpointing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "mqOY93sxLFbY"
   },
   "outputs": [],
   "source": [
    "vae = vae.to(torch_device)\n",
    "text_encoder = text_encoder.to(torch_device)\n",
    "unet = unet.to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "Gw1OChorLHGT"
   },
   "outputs": [],
   "source": [
    "if torch_device == \"cpu\":\n",
    "    cpu_offload_with_hook(vae, execution_device=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwNJT7RTLJ_q",
    "outputId": "3fdca442-f639-4926-90c8-04dbffc4a164"
   },
   "outputs": [],
   "source": [
    "def prune_unet_attention(unet_model):\n",
    "    for name, module in unet_model.named_modules():\n",
    "        if isinstance(module, BasicTransformerBlock):\n",
    "            for param_name, _ in module.named_parameters():\n",
    "                try:\n",
    "                    prune.random_unstructured(module, name=param_name, amount=0.2)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "prune_unet_attention(unet)\n",
    "\n",
    "# Optional attention map hook\n",
    "attention_maps = []\n",
    "def save_attention_hook(module, input, output):\n",
    "    if hasattr(output, 'attn_probs'):\n",
    "        attention_maps.append(output.attn_probs.detach().cpu())\n",
    "\n",
    "for name, module in unet.named_modules():\n",
    "    if isinstance(module, BasicTransformerBlock):\n",
    "        module.register_forward_hook(save_attention_hook)\n",
    "        print(f\"Hooked attention at layer: {name}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "1dp3pq22LSiM"
   },
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    \"A post-apocalyptic cityscape with crumbling, dilapidated skyscrapers overtaken by nature. \"\n",
    "    \"Vines and massive trees grow through shattered windows and collapsed roofs. The streets are cracked, \"\n",
    "    \"filled with roots and overgrowth. No signs of humans, just nature reclaiming the ruins. Moody lighting, \"\n",
    "    \"overcast skies, high detail, ultra-realistic, cinematic, 4K, concept art style.\"\n",
    "]\n",
    "height = 512\n",
    "width = 768\n",
    "num_inference_steps = 50\n",
    "guidance_scale = 7.5\n",
    "generator = torch.manual_seed(4)\n",
    "batch_size = 1\n",
    "\n",
    "# High-resolution mode\n",
    "if height > 512 or width > 768:\n",
    "    print(\"High-res mode activated.\")\n",
    "    num_inference_steps = int(num_inference_steps * 1.5)\n",
    "\n",
    "text_input = tokenizer(prompt, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]\n",
    "\n",
    "max_length = text_input.input_ids.shape[-1]\n",
    "uncond_input = tokenizer([\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]\n",
    "\n",
    "text_embeddings = torch.cat([uncond_embeddings, text_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcglO4_uLUR-",
    "outputId": "c1d4d6fd-dd14-41f7-b937-eca1d3bd2655"
   },
   "outputs": [],
   "source": [
    "scheduler.set_timesteps(num_inference_steps)\n",
    "latents = torch.randn((batch_size, unet.in_channels, height // 8, width // 8), generator=generator).to(torch_device)\n",
    "latents = latents * scheduler.sigmas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137,
     "referenced_widgets": [
      "e8ba3821cb814cf798b9bbe753978687",
      "8824686a42ef40be869efc2700308e91",
      "b10467b973d740c4b199c659e8d8e26c",
      "d0dbdfe5dd9d4f8a9244c5fa5f85ca34",
      "052045760b2f451a8013280e5872d1a9",
      "196187695d11466ebe0b986f66e95bad",
      "e493ea3071b24709b97707bebb62159c",
      "8314e4bdb3a0461eaa61cc7dc081de7c",
      "997de27d141f43349559bb4ee17d6c7d",
      "b763c7f03dc646e8b08d132ada8b2192",
      "704b019312114f02b623a95a93793279"
     ]
    },
    "id": "ZwIr-pt7LWYt",
    "outputId": "dd947120-4a68-408e-9141-673e5de73347"
   },
   "outputs": [],
   "source": [
    "autocast_context = autocast(\"cuda\") if use_amp else torch.no_grad()\n",
    "with autocast_context:\n",
    "    for t in tqdm(scheduler.timesteps):\n",
    "        latent_model_input = torch.cat([latents] * 2)\n",
    "        sigma = scheduler.sigmas[(scheduler.timesteps == t).nonzero(as_tuple=True)[0].item()]\n",
    "        latent_model_input = latent_model_input / ((sigma**2 + 1) ** 0.5)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings)[\"sample\"]\n",
    "\n",
    "        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "        noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "        latents = scheduler.step(noise_pred, t, latents)[\"prev_sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89cQjZVJLZMo",
    "outputId": "8fc3dc95-445c-4ac8-faf9-eafd8bf5579a"
   },
   "outputs": [],
   "source": [
    " tile_size=32\n",
    " def tile_latents(latents):\n",
    "    _, c, h, w = latents.shape\n",
    "    if h % tile_size != 0 or w % tile_size != 0:\n",
    "         raise ValueError(f\"Latent size ({h}, {w}) not divisible by tile size {tile_size}\")\n",
    "    tiles = []\n",
    "    for i in range(0, h, tile_size):\n",
    "        for j in range(0, w, tile_size):\n",
    "            tiles.append(latents[:, :, i:i+tile_size, j:j+tile_size])\n",
    "    return tiles\n",
    "\n",
    "tiles = tile_latents(latents)\n",
    "print(f\"Tiled into {len(tiles)} latent chunks with tile size {tile_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "BRhn0eoaLbX_"
   },
   "outputs": [],
   "source": [
    "latents = 1 / 0.18215 * latents\n",
    "with torch.no_grad():\n",
    "    decoded_output = vae.decode(latents)\n",
    "\n",
    "image_tensor = decoded_output.sample  # may need to update depending on your model\n",
    "image = (image_tensor / 2 + 0.5).clamp(0, 1)\n",
    "image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
    "images = (image * 255).round().astype(\"uint8\")\n",
    "pil_images = [Image.fromarray(img) for img in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Yso0KJ6LdTo",
    "outputId": "edba20d0-a1c7-4e00-828a-90ab99fa1ff4"
   },
   "outputs": [],
   "source": [
    "lpips_fn = LPIPS(net='vgg')\n",
    "def calc_lpips(image1, image2):\n",
    "    tensor1 = tfms.ToTensor()(image1).unsqueeze(0)\n",
    "    tensor2 = tfms.ToTensor()(image2).unsqueeze(0)\n",
    "    return lpips_fn(tensor1, tensor2).item()\n",
    "\n",
    "lpips_score = calc_lpips(pil_images[0], pil_images[0])\n",
    "print(\"LPIPS score (identity):\", lpips_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "xXNjl0-ULfay",
    "outputId": "176421f3-408e-447d-fd80-dd5961a2f34b"
   },
   "outputs": [],
   "source": [
    "def print_memory_stats():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\\n[Memory] Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "        print(f\"[Memory] Reserved : {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "\n",
    "print_memory_stats()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Show Image\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(pil_images[0])\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generated Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "rGAsBKR7LhRz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
